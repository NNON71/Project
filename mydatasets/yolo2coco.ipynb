{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d25f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from PIL import Image\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a07c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Converting YOLO dataset from d:/4-1d/project/data/indoor-dataset\n",
      "ðŸ“ Output will be saved to d:/4-1d/project/data/indoor-coco\n",
      "ðŸ·ï¸ Classes: ['door', 'cabinetDoor', 'refrigeratorDoor', 'window', 'chair', 'table', 'cabinet', 'couch', 'openedDoor', 'pole']\n",
      "ðŸš€ Starting YOLO to COCO conversion...\n",
      "\n",
      "ðŸ“Š Processing train split...\n",
      "ðŸ“· Found 2024 images\n",
      "  ðŸ“Š Processed 100 images...\n",
      "  ðŸ“Š Processed 200 images...\n",
      "  ðŸ“Š Processed 300 images...\n",
      "  ðŸ“Š Processed 400 images...\n",
      "  ðŸ“Š Processed 500 images...\n",
      "  ðŸ“Š Processed 600 images...\n",
      "  ðŸ“Š Processed 700 images...\n",
      "  ðŸ“Š Processed 800 images...\n",
      "  ðŸ“Š Processed 900 images...\n",
      "  ðŸ“Š Processed 1000 images...\n",
      "  ðŸ“Š Processed 1100 images...\n",
      "  ðŸ“Š Processed 1200 images...\n",
      "  ðŸ“Š Processed 1300 images...\n",
      "  ðŸ“Š Processed 1400 images...\n",
      "  ðŸ“Š Processed 1500 images...\n",
      "  ðŸ“Š Processed 1600 images...\n",
      "  ðŸ“Š Processed 1700 images...\n",
      "  ðŸ“Š Processed 1800 images...\n",
      "  ðŸ“Š Processed 1900 images...\n",
      "  ðŸ“Š Processed 2000 images...\n",
      "âœ… train conversion completed:\n",
      "  ðŸ“· Images: 2024\n",
      "  ðŸ·ï¸ Annotations: 10984\n",
      "  âŒ Errors: 0\n",
      "  ðŸ’¾ Saved to: d:\\4-1d\\project\\data\\indoor-coco\\annotations\\train.json\n",
      "\n",
      "ðŸ“Š Processing valid split...\n",
      "ðŸ“· Found 460 images\n",
      "  ðŸ“Š Processed 100 images...\n",
      "  ðŸ“Š Processed 200 images...\n",
      "  ðŸ“Š Processed 300 images...\n",
      "  ðŸ“Š Processed 400 images...\n",
      "âœ… valid conversion completed:\n",
      "  ðŸ“· Images: 460\n",
      "  ðŸ·ï¸ Annotations: 2578\n",
      "  âŒ Errors: 0\n",
      "  ðŸ’¾ Saved to: d:\\4-1d\\project\\data\\indoor-coco\\annotations\\valid.json\n",
      "\n",
      "ðŸ“Š Processing test split...\n",
      "ðŸ“· Found 214 images\n",
      "  ðŸ“Š Processed 100 images...\n",
      "  ðŸ“Š Processed 200 images...\n",
      "âœ… test conversion completed:\n",
      "  ðŸ“· Images: 214\n",
      "  ðŸ·ï¸ Annotations: 1100\n",
      "  âŒ Errors: 0\n",
      "  ðŸ’¾ Saved to: d:\\4-1d\\project\\data\\indoor-coco\\annotations\\test.json\n",
      "\n",
      "ðŸ“‹ Dataset Summary:\n",
      "  ðŸ“ Total Images: 2698\n",
      "  ðŸ·ï¸ Total Annotations: 14662\n",
      "  ðŸ“Š Splits: ['train', 'valid', 'test']\n",
      "  ðŸ’¾ Summary saved to: d:\\4-1d\\project\\data\\indoor-coco\\dataset_summary.json\n",
      "\n",
      "ðŸŽ‰ Conversion completed!\n"
     ]
    }
   ],
   "source": [
    "class YOLOtoCOCOConverter:\n",
    "    \"\"\"Convert YOLO format dataset to COCO format\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 yolo_dataset_path: str,\n",
    "                 output_path: str,\n",
    "                 class_names: List[str],\n",
    "                 thai_class_names: List[str] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            yolo_dataset_path: Path to YOLO dataset (contains images/ and labels/)\n",
    "            output_path: Output path for COCO format dataset\n",
    "            class_names: List of class names in English\n",
    "            thai_class_names: List of class names in Thai (optional)\n",
    "        \"\"\"\n",
    "        self.yolo_path = Path(yolo_dataset_path)\n",
    "        self.output_path = Path(output_path)\n",
    "        self.class_names = class_names\n",
    "        self.thai_class_names = thai_class_names or class_names\n",
    "        \n",
    "        # Create output directories\n",
    "        self.output_path.mkdir(parents=True, exist_ok=True)\n",
    "        (self.output_path / \"images\").mkdir(exist_ok=True)\n",
    "        (self.output_path / \"annotations\").mkdir(exist_ok=True)\n",
    "        \n",
    "        print(f\"ðŸ”„ Converting YOLO dataset from {yolo_dataset_path}\")\n",
    "        print(f\"ðŸ“ Output will be saved to {output_path}\")\n",
    "        print(f\"ðŸ·ï¸ Classes: {self.class_names}\")\n",
    "    \n",
    "    def convert_bbox_yolo_to_coco(self, \n",
    "                                  yolo_bbox: List[float], \n",
    "                                  img_width: int, \n",
    "                                  img_height: int) -> List[float]:\n",
    "        \"\"\"\n",
    "        Convert YOLO bbox format to COCO format\n",
    "        \n",
    "        YOLO: [x_center, y_center, width, height] (normalized 0-1)\n",
    "        COCO: [x_min, y_min, width, height] (absolute pixels)\n",
    "        \"\"\"\n",
    "        x_center, y_center, width, height = yolo_bbox\n",
    "        \n",
    "        # Convert to absolute coordinates\n",
    "        x_center_abs = x_center * img_width\n",
    "        y_center_abs = y_center * img_height\n",
    "        width_abs = width * img_width\n",
    "        height_abs = height * img_height\n",
    "        \n",
    "        # Convert to top-left corner format\n",
    "        x_min = x_center_abs - (width_abs / 2)\n",
    "        y_min = y_center_abs - (height_abs / 2)\n",
    "        \n",
    "        # Ensure coordinates are within image bounds\n",
    "        x_min = max(0, min(x_min, img_width - 1))\n",
    "        y_min = max(0, min(y_min, img_height - 1))\n",
    "        width_abs = min(width_abs, img_width - x_min)\n",
    "        height_abs = min(height_abs, img_height - y_min)\n",
    "        \n",
    "        return [x_min, y_min, width_abs, height_abs]\n",
    "    \n",
    "    def process_split(self, split_name: str) -> Dict:\n",
    "        \"\"\"Process train/val/test split\"\"\"\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Processing {split_name} split...\")\n",
    "        \n",
    "        # Paths\n",
    "        images_dir = self.yolo_path / split_name / \"images\"\n",
    "        labels_dir = self.yolo_path / split_name / \"labels\"\n",
    "        \n",
    "        if not images_dir.exists():\n",
    "            print(f\"âš ï¸ Images directory not found: {images_dir}\")\n",
    "            return {}\n",
    "        \n",
    "        if not labels_dir.exists():\n",
    "            print(f\"âš ï¸ Labels directory not found: {labels_dir}\")\n",
    "            return {}\n",
    "        \n",
    "        # COCO format structure\n",
    "        coco_data = {\n",
    "            \"info\": {\n",
    "                \"description\": f\"Indoor Object Detection Dataset - {split_name}\",\n",
    "                \"version\": \"1.0\",\n",
    "                \"year\": 2024,\n",
    "                \"contributor\": \"Converted from YOLO format\",\n",
    "                \"date_created\": \"2024-01-01\"\n",
    "            },\n",
    "            \"licenses\": [\n",
    "                {\n",
    "                    \"id\": 1,\n",
    "                    \"name\": \"Unknown\",\n",
    "                    \"url\": \"\"\n",
    "                }\n",
    "            ],\n",
    "            \"images\": [],\n",
    "            \"annotations\": [],\n",
    "            \"categories\": []\n",
    "        }\n",
    "        \n",
    "        # Add categories\n",
    "        for idx, (class_name, thai_name) in enumerate(zip(self.class_names, self.thai_class_names)):\n",
    "            coco_data[\"categories\"].append({\n",
    "                \"id\": idx,\n",
    "                \"name\": class_name,\n",
    "                \"thai_name\": thai_name,\n",
    "                \"supercategory\": \"indoor_object\"\n",
    "            })\n",
    "        \n",
    "        # Copy images and process annotations\n",
    "        output_images_dir = self.output_path / \"images\" / split_name\n",
    "        output_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        image_id = 1\n",
    "        annotation_id = 1\n",
    "        processed_count = 0\n",
    "        error_count = 0\n",
    "        \n",
    "        # Get all image files\n",
    "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "        image_files = []\n",
    "        for ext in image_extensions:\n",
    "            image_files.extend(list(images_dir.glob(f\"*{ext}\")))\n",
    "            image_files.extend(list(images_dir.glob(f\"*{ext.upper()}\")))\n",
    "        \n",
    "        print(f\"ðŸ“· Found {len(image_files)} images\")\n",
    "        \n",
    "        for image_path in image_files:\n",
    "            try:\n",
    "                # Load image to get dimensions\n",
    "                image = Image.open(image_path)\n",
    "                img_width, img_height = image.size\n",
    "                \n",
    "                # Copy image to output directory\n",
    "                output_image_path = output_images_dir / image_path.name\n",
    "                shutil.copy2(image_path, output_image_path)\n",
    "                \n",
    "                # Add image info\n",
    "                coco_data[\"images\"].append({\n",
    "                    \"id\": image_id,\n",
    "                    \"file_name\": f\"{split_name}/{image_path.name}\",\n",
    "                    \"width\": img_width,\n",
    "                    \"height\": img_height,\n",
    "                    \"license\": 1\n",
    "                })\n",
    "                \n",
    "                # Process corresponding label file\n",
    "                label_path = labels_dir / f\"{image_path.stem}.txt\"\n",
    "                \n",
    "                if label_path.exists():\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                    \n",
    "                    for line in lines:\n",
    "                        line = line.strip()\n",
    "                        if not line:\n",
    "                            continue\n",
    "                        \n",
    "                        try:\n",
    "                            parts = line.split()\n",
    "                            if len(parts) != 5:\n",
    "                                print(f\"âš ï¸ Invalid annotation format in {label_path}: {line}\")\n",
    "                                continue\n",
    "                            \n",
    "                            class_id = int(parts[0])\n",
    "                            x_center = float(parts[1])\n",
    "                            y_center = float(parts[2])\n",
    "                            width = float(parts[3])\n",
    "                            height = float(parts[4])\n",
    "                            \n",
    "                            # Validate class_id\n",
    "                            if class_id >= len(self.class_names):\n",
    "                                print(f\"âš ï¸ Invalid class_id {class_id} in {label_path}\")\n",
    "                                continue\n",
    "                            \n",
    "                            # Convert bbox\n",
    "                            yolo_bbox = [x_center, y_center, width, height]\n",
    "                            coco_bbox = self.convert_bbox_yolo_to_coco(yolo_bbox, img_width, img_height)\n",
    "                            \n",
    "                            # Calculate area\n",
    "                            area = coco_bbox[2] * coco_bbox[3]\n",
    "                            \n",
    "                            # Add annotation\n",
    "                            coco_data[\"annotations\"].append({\n",
    "                                \"id\": annotation_id,\n",
    "                                \"image_id\": image_id,\n",
    "                                \"category_id\": class_id,\n",
    "                                \"bbox\": coco_bbox,\n",
    "                                \"area\": area,\n",
    "                                \"iscrowd\": 0,\n",
    "                                \"segmentation\": []\n",
    "                            })\n",
    "                            \n",
    "                            annotation_id += 1\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"âš ï¸ Error processing annotation {line} in {label_path}: {e}\")\n",
    "                            continue\n",
    "                \n",
    "                image_id += 1\n",
    "                processed_count += 1\n",
    "                \n",
    "                if processed_count % 100 == 0:\n",
    "                    print(f\"  ðŸ“Š Processed {processed_count} images...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error processing {image_path}: {e}\")\n",
    "                error_count += 1\n",
    "                continue\n",
    "        \n",
    "        # Save COCO annotations\n",
    "        output_annotation_path = self.output_path / \"annotations\" / f\"{split_name}.json\"\n",
    "        with open(output_annotation_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(coco_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"âœ… {split_name} conversion completed:\")\n",
    "        print(f\"  ðŸ“· Images: {len(coco_data['images'])}\")\n",
    "        print(f\"  ðŸ·ï¸ Annotations: {len(coco_data['annotations'])}\")\n",
    "        print(f\"  âŒ Errors: {error_count}\")\n",
    "        print(f\"  ðŸ’¾ Saved to: {output_annotation_path}\")\n",
    "        \n",
    "        return coco_data\n",
    "    \n",
    "    def convert_dataset(self):\n",
    "        \"\"\"Convert entire dataset\"\"\"\n",
    "        print(\"ðŸš€ Starting YOLO to COCO conversion...\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Process each split\n",
    "        for split in ['train', 'valid', 'test']:\n",
    "            split_path = self.yolo_path / split\n",
    "            if split_path.exists():\n",
    "                results[split] = self.process_split(split)\n",
    "            else:\n",
    "                print(f\"âš ï¸ Split {split} not found, skipping...\")\n",
    "        \n",
    "        # Create summary\n",
    "        self.create_summary(results)\n",
    "        \n",
    "        print(\"\\nðŸŽ‰ Conversion completed!\")\n",
    "        return results\n",
    "    \n",
    "    def create_summary(self, results: Dict):\n",
    "        \"\"\"Create conversion summary\"\"\"\n",
    "        summary = {\n",
    "            \"dataset_info\": {\n",
    "                \"name\": \"Indoor Object Detection Dataset\",\n",
    "                \"format\": \"COCO\",\n",
    "                \"converted_from\": \"YOLO\",\n",
    "                \"classes\": {\n",
    "                    \"count\": len(self.class_names),\n",
    "                    \"names\": self.class_names,\n",
    "                    \"thai_names\": self.thai_class_names\n",
    "                }\n",
    "            },\n",
    "            \"splits\": {}\n",
    "        }\n",
    "        \n",
    "        total_images = 0\n",
    "        total_annotations = 0\n",
    "        \n",
    "        for split_name, split_data in results.items():\n",
    "            if split_data:\n",
    "                split_summary = {\n",
    "                    \"images\": len(split_data[\"images\"]),\n",
    "                    \"annotations\": len(split_data[\"annotations\"]),\n",
    "                    \"categories\": len(split_data[\"categories\"])\n",
    "                }\n",
    "                summary[\"splits\"][split_name] = split_summary\n",
    "                total_images += split_summary[\"images\"]\n",
    "                total_annotations += split_summary[\"annotations\"]\n",
    "        \n",
    "        summary[\"totals\"] = {\n",
    "            \"images\": total_images,\n",
    "            \"annotations\": total_annotations\n",
    "        }\n",
    "        \n",
    "        # Save summary\n",
    "        summary_path = self.output_path / \"dataset_summary.json\"\n",
    "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\nðŸ“‹ Dataset Summary:\")\n",
    "        print(f\"  ðŸ“ Total Images: {total_images}\")\n",
    "        print(f\"  ðŸ·ï¸ Total Annotations: {total_annotations}\")\n",
    "        print(f\"  ðŸ“Š Splits: {list(results.keys())}\")\n",
    "        print(f\"  ðŸ’¾ Summary saved to: {summary_path}\")\n",
    "\n",
    "def convert_indoor_dataset():\n",
    "    \"\"\"Convert indoor object detection dataset\"\"\"\n",
    "    \n",
    "    # Define class names\n",
    "    class_names = [\n",
    "        \"door\", \"cabinetDoor\", \"refrigeratorDoor\", \"window\", \"chair\",\n",
    "        \"table\", \"cabinet\", \"couch\", \"openedDoor\", \"pole\"\n",
    "    ]\n",
    "    \n",
    "    thai_class_names = [\n",
    "        \"à¸›à¸£à¸°à¸•à¸¹\", \"à¸›à¸£à¸°à¸•à¸¹à¸•à¸¹à¹‰\", \"à¸›à¸£à¸°à¸•à¸¹à¸•à¸¹à¹‰à¹€à¸¢à¹‡à¸™\", \"à¸«à¸™à¹‰à¸²à¸•à¹ˆà¸²à¸‡\", \"à¹€à¸à¹‰à¸²à¸­à¸µà¹‰\",\n",
    "        \"à¹‚à¸•à¹Šà¸°\", \"à¸•à¸¹à¹‰\", \"à¹‚à¸‹à¸Ÿà¸²\", \"à¸›à¸£à¸°à¸•à¸¹à¹€à¸›à¸´à¸”\", \"à¹€à¸ªà¸²\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize converter\n",
    "    converter = YOLOtoCOCOConverter(\n",
    "        yolo_dataset_path=\"d:/4-1d/project/data/indoor-dataset\",\n",
    "        output_path=\"d:/4-1d/project/data/indoor-coco\",\n",
    "        class_names=class_names,\n",
    "        thai_class_names=thai_class_names\n",
    "    )\n",
    "    \n",
    "    # Convert dataset\n",
    "    results = converter.convert_dataset()\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_indoor_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59fe62da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\4-1d\\project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a555b2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'pwd'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpwd\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: module 'os' has no attribute 'pwd'"
     ]
    }
   ],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffa7753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\4-1d\\\\project\\\\mydatasets'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pwd\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6707fa2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'filepath', 'sentids', 'filename', 'imgid', 'split', 'sentences_tokens', 'sentences_raw', 'sentences_sentid', 'cocoid', 'th_sentences_raw'],\n",
       "        num_rows: 113287\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'filepath', 'sentids', 'filename', 'imgid', 'split', 'sentences_tokens', 'sentences_raw', 'sentences_sentid', 'cocoid', 'th_sentences_raw'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'filepath', 'sentids', 'filename', 'imgid', 'split', 'sentences_tokens', 'sentences_raw', 'sentences_sentid', 'cocoid', 'th_sentences_raw'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(\"patomp/thai-mscoco-2014-captions\", cache_dir=\"../data/huggingface/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6598871c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0+cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
