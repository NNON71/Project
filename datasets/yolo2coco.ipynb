{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d25f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from PIL import Image\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a07c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting YOLO dataset from d:/4-1d/project/data/indoor-dataset\n",
      "üìÅ Output will be saved to d:/4-1d/project/data/indoor-coco\n",
      "üè∑Ô∏è Classes: ['door', 'cabinetDoor', 'refrigeratorDoor', 'window', 'chair', 'table', 'cabinet', 'couch', 'openedDoor', 'pole']\n",
      "üöÄ Starting YOLO to COCO conversion...\n",
      "\n",
      "üìä Processing train split...\n",
      "üì∑ Found 2024 images\n",
      "  üìä Processed 100 images...\n",
      "  üìä Processed 200 images...\n",
      "  üìä Processed 300 images...\n",
      "  üìä Processed 400 images...\n",
      "  üìä Processed 500 images...\n",
      "  üìä Processed 600 images...\n",
      "  üìä Processed 700 images...\n",
      "  üìä Processed 800 images...\n",
      "  üìä Processed 900 images...\n",
      "  üìä Processed 1000 images...\n",
      "  üìä Processed 1100 images...\n",
      "  üìä Processed 1200 images...\n",
      "  üìä Processed 1300 images...\n",
      "  üìä Processed 1400 images...\n",
      "  üìä Processed 1500 images...\n",
      "  üìä Processed 1600 images...\n",
      "  üìä Processed 1700 images...\n",
      "  üìä Processed 1800 images...\n",
      "  üìä Processed 1900 images...\n",
      "  üìä Processed 2000 images...\n",
      "‚úÖ train conversion completed:\n",
      "  üì∑ Images: 2024\n",
      "  üè∑Ô∏è Annotations: 10984\n",
      "  ‚ùå Errors: 0\n",
      "  üíæ Saved to: d:\\4-1d\\project\\data\\indoor-coco\\annotations\\train.json\n",
      "\n",
      "üìä Processing valid split...\n",
      "üì∑ Found 460 images\n",
      "  üìä Processed 100 images...\n",
      "  üìä Processed 200 images...\n",
      "  üìä Processed 300 images...\n",
      "  üìä Processed 400 images...\n",
      "‚úÖ valid conversion completed:\n",
      "  üì∑ Images: 460\n",
      "  üè∑Ô∏è Annotations: 2578\n",
      "  ‚ùå Errors: 0\n",
      "  üíæ Saved to: d:\\4-1d\\project\\data\\indoor-coco\\annotations\\valid.json\n",
      "\n",
      "üìä Processing test split...\n",
      "üì∑ Found 214 images\n",
      "  üìä Processed 100 images...\n",
      "  üìä Processed 200 images...\n",
      "‚úÖ test conversion completed:\n",
      "  üì∑ Images: 214\n",
      "  üè∑Ô∏è Annotations: 1100\n",
      "  ‚ùå Errors: 0\n",
      "  üíæ Saved to: d:\\4-1d\\project\\data\\indoor-coco\\annotations\\test.json\n",
      "\n",
      "üìã Dataset Summary:\n",
      "  üìÅ Total Images: 2698\n",
      "  üè∑Ô∏è Total Annotations: 14662\n",
      "  üìä Splits: ['train', 'valid', 'test']\n",
      "  üíæ Summary saved to: d:\\4-1d\\project\\data\\indoor-coco\\dataset_summary.json\n",
      "\n",
      "üéâ Conversion completed!\n"
     ]
    }
   ],
   "source": [
    "class YOLOtoCOCOConverter:\n",
    "    \"\"\"Convert YOLO format dataset to COCO format\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 yolo_dataset_path: str,\n",
    "                 output_path: str,\n",
    "                 class_names: List[str],\n",
    "                 thai_class_names: List[str] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            yolo_dataset_path: Path to YOLO dataset (contains images/ and labels/)\n",
    "            output_path: Output path for COCO format dataset\n",
    "            class_names: List of class names in English\n",
    "            thai_class_names: List of class names in Thai (optional)\n",
    "        \"\"\"\n",
    "        self.yolo_path = Path(yolo_dataset_path)\n",
    "        self.output_path = Path(output_path)\n",
    "        self.class_names = class_names\n",
    "        self.thai_class_names = thai_class_names or class_names\n",
    "        \n",
    "        # Create output directories\n",
    "        self.output_path.mkdir(parents=True, exist_ok=True)\n",
    "        (self.output_path / \"images\").mkdir(exist_ok=True)\n",
    "        (self.output_path / \"annotations\").mkdir(exist_ok=True)\n",
    "        \n",
    "        print(f\"üîÑ Converting YOLO dataset from {yolo_dataset_path}\")\n",
    "        print(f\"üìÅ Output will be saved to {output_path}\")\n",
    "        print(f\"üè∑Ô∏è Classes: {self.class_names}\")\n",
    "    \n",
    "    def convert_bbox_yolo_to_coco(self, \n",
    "                                  yolo_bbox: List[float], \n",
    "                                  img_width: int, \n",
    "                                  img_height: int) -> List[float]:\n",
    "        \"\"\"\n",
    "        Convert YOLO bbox format to COCO format\n",
    "        \n",
    "        YOLO: [x_center, y_center, width, height] (normalized 0-1)\n",
    "        COCO: [x_min, y_min, width, height] (absolute pixels)\n",
    "        \"\"\"\n",
    "        x_center, y_center, width, height = yolo_bbox\n",
    "        \n",
    "        # Convert to absolute coordinates\n",
    "        x_center_abs = x_center * img_width\n",
    "        y_center_abs = y_center * img_height\n",
    "        width_abs = width * img_width\n",
    "        height_abs = height * img_height\n",
    "        \n",
    "        # Convert to top-left corner format\n",
    "        x_min = x_center_abs - (width_abs / 2)\n",
    "        y_min = y_center_abs - (height_abs / 2)\n",
    "        \n",
    "        # Ensure coordinates are within image bounds\n",
    "        x_min = max(0, min(x_min, img_width - 1))\n",
    "        y_min = max(0, min(y_min, img_height - 1))\n",
    "        width_abs = min(width_abs, img_width - x_min)\n",
    "        height_abs = min(height_abs, img_height - y_min)\n",
    "        \n",
    "        return [x_min, y_min, width_abs, height_abs]\n",
    "    \n",
    "    def process_split(self, split_name: str) -> Dict:\n",
    "        \"\"\"Process train/val/test split\"\"\"\n",
    "        \n",
    "        print(f\"\\nüìä Processing {split_name} split...\")\n",
    "        \n",
    "        # Paths\n",
    "        images_dir = self.yolo_path / split_name / \"images\"\n",
    "        labels_dir = self.yolo_path / split_name / \"labels\"\n",
    "        \n",
    "        if not images_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è Images directory not found: {images_dir}\")\n",
    "            return {}\n",
    "        \n",
    "        if not labels_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è Labels directory not found: {labels_dir}\")\n",
    "            return {}\n",
    "        \n",
    "        # COCO format structure\n",
    "        coco_data = {\n",
    "            \"info\": {\n",
    "                \"description\": f\"Indoor Object Detection Dataset - {split_name}\",\n",
    "                \"version\": \"1.0\",\n",
    "                \"year\": 2024,\n",
    "                \"contributor\": \"Converted from YOLO format\",\n",
    "                \"date_created\": \"2024-01-01\"\n",
    "            },\n",
    "            \"licenses\": [\n",
    "                {\n",
    "                    \"id\": 1,\n",
    "                    \"name\": \"Unknown\",\n",
    "                    \"url\": \"\"\n",
    "                }\n",
    "            ],\n",
    "            \"images\": [],\n",
    "            \"annotations\": [],\n",
    "            \"categories\": []\n",
    "        }\n",
    "        \n",
    "        # Add categories\n",
    "        for idx, (class_name, thai_name) in enumerate(zip(self.class_names, self.thai_class_names)):\n",
    "            coco_data[\"categories\"].append({\n",
    "                \"id\": idx,\n",
    "                \"name\": class_name,\n",
    "                \"thai_name\": thai_name,\n",
    "                \"supercategory\": \"indoor_object\"\n",
    "            })\n",
    "        \n",
    "        # Copy images and process annotations\n",
    "        output_images_dir = self.output_path / \"images\" / split_name\n",
    "        output_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        image_id = 1\n",
    "        annotation_id = 1\n",
    "        processed_count = 0\n",
    "        error_count = 0\n",
    "        \n",
    "        # Get all image files\n",
    "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "        image_files = []\n",
    "        for ext in image_extensions:\n",
    "            image_files.extend(list(images_dir.glob(f\"*{ext}\")))\n",
    "            image_files.extend(list(images_dir.glob(f\"*{ext.upper()}\")))\n",
    "        \n",
    "        print(f\"üì∑ Found {len(image_files)} images\")\n",
    "        \n",
    "        for image_path in image_files:\n",
    "            try:\n",
    "                # Load image to get dimensions\n",
    "                image = Image.open(image_path)\n",
    "                img_width, img_height = image.size\n",
    "                \n",
    "                # Copy image to output directory\n",
    "                output_image_path = output_images_dir / image_path.name\n",
    "                shutil.copy2(image_path, output_image_path)\n",
    "                \n",
    "                # Add image info\n",
    "                coco_data[\"images\"].append({\n",
    "                    \"id\": image_id,\n",
    "                    \"file_name\": f\"{split_name}/{image_path.name}\",\n",
    "                    \"width\": img_width,\n",
    "                    \"height\": img_height,\n",
    "                    \"license\": 1\n",
    "                })\n",
    "                \n",
    "                # Process corresponding label file\n",
    "                label_path = labels_dir / f\"{image_path.stem}.txt\"\n",
    "                \n",
    "                if label_path.exists():\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                    \n",
    "                    for line in lines:\n",
    "                        line = line.strip()\n",
    "                        if not line:\n",
    "                            continue\n",
    "                        \n",
    "                        try:\n",
    "                            parts = line.split()\n",
    "                            if len(parts) != 5:\n",
    "                                print(f\"‚ö†Ô∏è Invalid annotation format in {label_path}: {line}\")\n",
    "                                continue\n",
    "                            \n",
    "                            class_id = int(parts[0])\n",
    "                            x_center = float(parts[1])\n",
    "                            y_center = float(parts[2])\n",
    "                            width = float(parts[3])\n",
    "                            height = float(parts[4])\n",
    "                            \n",
    "                            # Validate class_id\n",
    "                            if class_id >= len(self.class_names):\n",
    "                                print(f\"‚ö†Ô∏è Invalid class_id {class_id} in {label_path}\")\n",
    "                                continue\n",
    "                            \n",
    "                            # Convert bbox\n",
    "                            yolo_bbox = [x_center, y_center, width, height]\n",
    "                            coco_bbox = self.convert_bbox_yolo_to_coco(yolo_bbox, img_width, img_height)\n",
    "                            \n",
    "                            # Calculate area\n",
    "                            area = coco_bbox[2] * coco_bbox[3]\n",
    "                            \n",
    "                            # Add annotation\n",
    "                            coco_data[\"annotations\"].append({\n",
    "                                \"id\": annotation_id,\n",
    "                                \"image_id\": image_id,\n",
    "                                \"category_id\": class_id,\n",
    "                                \"bbox\": coco_bbox,\n",
    "                                \"area\": area,\n",
    "                                \"iscrowd\": 0,\n",
    "                                \"segmentation\": []\n",
    "                            })\n",
    "                            \n",
    "                            annotation_id += 1\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"‚ö†Ô∏è Error processing annotation {line} in {label_path}: {e}\")\n",
    "                            continue\n",
    "                \n",
    "                image_id += 1\n",
    "                processed_count += 1\n",
    "                \n",
    "                if processed_count % 100 == 0:\n",
    "                    print(f\"  üìä Processed {processed_count} images...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing {image_path}: {e}\")\n",
    "                error_count += 1\n",
    "                continue\n",
    "        \n",
    "        # Save COCO annotations\n",
    "        output_annotation_path = self.output_path / \"annotations\" / f\"{split_name}.json\"\n",
    "        with open(output_annotation_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(coco_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"‚úÖ {split_name} conversion completed:\")\n",
    "        print(f\"  üì∑ Images: {len(coco_data['images'])}\")\n",
    "        print(f\"  üè∑Ô∏è Annotations: {len(coco_data['annotations'])}\")\n",
    "        print(f\"  ‚ùå Errors: {error_count}\")\n",
    "        print(f\"  üíæ Saved to: {output_annotation_path}\")\n",
    "        \n",
    "        return coco_data\n",
    "    \n",
    "    def convert_dataset(self):\n",
    "        \"\"\"Convert entire dataset\"\"\"\n",
    "        print(\"üöÄ Starting YOLO to COCO conversion...\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Process each split\n",
    "        for split in ['train', 'valid', 'test']:\n",
    "            split_path = self.yolo_path / split\n",
    "            if split_path.exists():\n",
    "                results[split] = self.process_split(split)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Split {split} not found, skipping...\")\n",
    "        \n",
    "        # Create summary\n",
    "        self.create_summary(results)\n",
    "        \n",
    "        print(\"\\nüéâ Conversion completed!\")\n",
    "        return results\n",
    "    \n",
    "    def create_summary(self, results: Dict):\n",
    "        \"\"\"Create conversion summary\"\"\"\n",
    "        summary = {\n",
    "            \"dataset_info\": {\n",
    "                \"name\": \"Indoor Object Detection Dataset\",\n",
    "                \"format\": \"COCO\",\n",
    "                \"converted_from\": \"YOLO\",\n",
    "                \"classes\": {\n",
    "                    \"count\": len(self.class_names),\n",
    "                    \"names\": self.class_names,\n",
    "                    \"thai_names\": self.thai_class_names\n",
    "                }\n",
    "            },\n",
    "            \"splits\": {}\n",
    "        }\n",
    "        \n",
    "        total_images = 0\n",
    "        total_annotations = 0\n",
    "        \n",
    "        for split_name, split_data in results.items():\n",
    "            if split_data:\n",
    "                split_summary = {\n",
    "                    \"images\": len(split_data[\"images\"]),\n",
    "                    \"annotations\": len(split_data[\"annotations\"]),\n",
    "                    \"categories\": len(split_data[\"categories\"])\n",
    "                }\n",
    "                summary[\"splits\"][split_name] = split_summary\n",
    "                total_images += split_summary[\"images\"]\n",
    "                total_annotations += split_summary[\"annotations\"]\n",
    "        \n",
    "        summary[\"totals\"] = {\n",
    "            \"images\": total_images,\n",
    "            \"annotations\": total_annotations\n",
    "        }\n",
    "        \n",
    "        # Save summary\n",
    "        summary_path = self.output_path / \"dataset_summary.json\"\n",
    "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\nüìã Dataset Summary:\")\n",
    "        print(f\"  üìÅ Total Images: {total_images}\")\n",
    "        print(f\"  üè∑Ô∏è Total Annotations: {total_annotations}\")\n",
    "        print(f\"  üìä Splits: {list(results.keys())}\")\n",
    "        print(f\"  üíæ Summary saved to: {summary_path}\")\n",
    "\n",
    "def convert_indoor_dataset():\n",
    "    \"\"\"Convert indoor object detection dataset\"\"\"\n",
    "    \n",
    "    # Define class names\n",
    "    class_names = [\n",
    "        \"door\", \"cabinetDoor\", \"refrigeratorDoor\", \"window\", \"chair\",\n",
    "        \"table\", \"cabinet\", \"couch\", \"openedDoor\", \"pole\"\n",
    "    ]\n",
    "    \n",
    "    thai_class_names = [\n",
    "        \"‡∏õ‡∏£‡∏∞‡∏ï‡∏π\", \"‡∏õ‡∏£‡∏∞‡∏ï‡∏π‡∏ï‡∏π‡πâ\", \"‡∏õ‡∏£‡∏∞‡∏ï‡∏π‡∏ï‡∏π‡πâ‡πÄ‡∏¢‡πá‡∏ô\", \"‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á\", \"‡πÄ‡∏Å‡πâ‡∏≤‡∏≠‡∏µ‡πâ\",\n",
    "        \"‡πÇ‡∏ï‡πä‡∏∞\", \"‡∏ï‡∏π‡πâ\", \"‡πÇ‡∏ã‡∏ü‡∏≤\", \"‡∏õ‡∏£‡∏∞‡∏ï‡∏π‡πÄ‡∏õ‡∏¥‡∏î\", \"‡πÄ‡∏™‡∏≤\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize converter\n",
    "    converter = YOLOtoCOCOConverter(\n",
    "        yolo_dataset_path=\"d:/4-1d/project/data/indoor-dataset\",\n",
    "        output_path=\"d:/4-1d/project/data/indoor-coco\",\n",
    "        class_names=class_names,\n",
    "        thai_class_names=thai_class_names\n",
    "    )\n",
    "    \n",
    "    # Convert dataset\n",
    "    results = converter.convert_dataset()\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_indoor_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
